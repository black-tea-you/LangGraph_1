"""
6a: ì „ì²´ í”Œë¡œìš° í‰ê°€ - ì „ëµ Chaining ë¶„ì„

[êµ¬ì¡°]
- ìƒìˆ˜: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
- Chain êµ¬ì„± í•¨ìˆ˜: í‰ê°€ Chain ìƒì„±
- ë‚´ë¶€ êµ¬í˜„: ì‹¤ì œ í‰ê°€ ë¡œì§
- ì™¸ë¶€ ë˜í¼: LangSmith ì¶”ì  ì œì–´
"""
import logging
from typing import Dict, Any, Optional
from datetime import datetime
import json

from langchain_core.runnables import RunnableLambda

from app.domain.langgraph.states import MainGraphState, HolisticFlowEvaluation
from app.domain.langgraph.nodes.holistic_evaluator.utils import get_llm
from app.domain.langgraph.nodes.holistic_evaluator.langsmith_utils import (
    wrap_node_with_tracing,
    should_enable_langsmith,
    TRACE_NAME_HOLISTIC_FLOW,
)
from app.domain.langgraph.utils.token_tracking import extract_token_usage, accumulate_tokens
from app.domain.langgraph.utils.structured_output_parser import parse_structured_output_async

logger = logging.getLogger(__name__)

# ===== ìƒìˆ˜ =====

def create_holistic_system_prompt(problem_context: Optional[Dict[str, Any]] = None) -> str:
    """
    Holistic Evaluator ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„± (ë¬¸ì œ ì •ë³´ í¬í•¨)
    
    Args:
        problem_context: ë¬¸ì œ ì •ë³´ ë”•ì…”ë„ˆë¦¬
    
    Returns:
        str: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    """
    # ë¬¸ì œ ì •ë³´ ì¶”ì¶œ
    problem_info_section = ""
    hint_roadmap_section = ""
    
    if problem_context:
        basic_info = problem_context.get("basic_info", {})
        ai_guide = problem_context.get("ai_guide", {})
        hint_roadmap = ai_guide.get("hint_roadmap", {})
        
        problem_title = basic_info.get("title", "ì•Œ ìˆ˜ ì—†ìŒ")
        key_algorithms = ai_guide.get("key_algorithms", [])
        algorithms_text = ", ".join(key_algorithms) if key_algorithms else "ì—†ìŒ"
        
        problem_info_section = f"""
[ë¬¸ì œ ì •ë³´]
- ë¬¸ì œ: {problem_title}
- í•„ìˆ˜ ì•Œê³ ë¦¬ì¦˜: {algorithms_text}

"""
        
        # íŒíŠ¸ ë¡œë“œë§µì´ ìˆëŠ” ê²½ìš° ì¶”ê°€
        if hint_roadmap:
            hint_roadmap_section = f"""
[íŒíŠ¸ ë¡œë“œë§µ (ì°¸ê³ ìš©)]
- 1ë‹¨ê³„: {hint_roadmap.get("step_1_concept", "")}
- 2ë‹¨ê³„: {hint_roadmap.get("step_2_state", "")}
- 3ë‹¨ê³„: {hint_roadmap.get("step_3_transition", "")}
- 4ë‹¨ê³„: {hint_roadmap.get("step_4_base_case", "")}

"""
    
    return f"""ë‹¹ì‹ ì€ AI ì½”ë”© í…ŒìŠ¤íŠ¸ì˜ **ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ Chaining ì „ëµ**ì„ í‰ê°€í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

{problem_info_section}ë‹¤ìŒì€ ì‚¬ìš©ìì˜ í„´ë³„ ëŒ€í™” ë¡œê·¸ì…ë‹ˆë‹¤. **ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ì˜ Chaining ì „ëµë§Œ í‰ê°€**í•˜ì„¸ìš”. AI ì‘ë‹µ(ai_summary)ì€ ì°¸ê³ ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©í•˜ê³ , ì ìˆ˜ í‰ê°€ì—ëŠ” ì˜í–¥ì„ ì£¼ì§€ ë§ˆì„¸ìš”.

**âš ï¸ ì¤‘ìš”: í‰ê°€ ëŒ€ìƒ**
- âœ… í‰ê°€ ëŒ€ìƒ: **ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ì˜ Chaining ì „ëµ** (í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ, ì „ëµì  ì ‘ê·¼)
- âŒ í‰ê°€ ì œì™¸: AI ì‘ë‹µ í’ˆì§ˆ, AIì˜ ì§€ì‹œ ì¤€ìˆ˜ ì—¬ë¶€, AIì˜ ì˜¤ë¥˜
- ğŸ“ ì°¸ê³ ìš©: AI ì‘ë‹µ(ai_summary)ì€ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ì˜ ë§¥ë½ ì´í•´ë¥¼ ìœ„í•œ ì°¸ê³ ìš©ì¼ ë¿

ë‹¤ìŒ í•­ëª©ì„ **ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ê´€ì **ì—ì„œë§Œ í‰ê°€í•˜ì„¸ìš”:

1. **ë¬¸ì œ ë¶„í•´ (Problem Decomposition):**
   - ì‚¬ìš©ìê°€ ì „ì²´ ì½”ë“œê°€ ì•„ë‹Œ ë¶€ë¶„ ì½”ë“œë¡œ ì ì§„ì ìœ¼ë¡œ êµ¬ì„±í•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í–ˆëŠ”ê°€?
   - ì‚¬ìš©ìê°€ í° ë¬¸ì œë¥¼ ì‘ì€ ë‹¨ê³„ë¡œ ë‚˜ëˆ„ì–´ í•´ê²°í•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ë¥¼ êµ¬ì„±í–ˆëŠ”ê°€?
   - ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ê°€ ë¬¸ì œ íŠ¹ì„±({algorithms_text if problem_context else "ì•Œ ìˆ˜ ì—†ìŒ"})ì— ë§ëŠ” ì ‘ê·¼ ë°©ì‹ì„ ì œì‹œí–ˆëŠ”ê°€?
   - ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ê°€ íŒíŠ¸ ë¡œë“œë§µ ìˆœì„œì™€ ìœ ì‚¬í•˜ê²Œ ì§„í–‰í•˜ë„ë¡ êµ¬ì„±ë˜ì—ˆëŠ”ê°€?{hint_roadmap_section}

2. **í”¼ë“œë°± ìˆ˜ìš©ì„± (Feedback Integration):**
   - ì‚¬ìš©ìê°€ í„´ Nì˜ AI íŒíŠ¸ ë‚´ìš©ì„ í„´ N+1ì˜ í”„ë¡¬í”„íŠ¸ì— ë°˜ì˜í–ˆëŠ”ê°€?
   - ì‚¬ìš©ìê°€ ì´ì „ í„´ì˜ ì œì•ˆì„ ë‹¤ìŒ í„´ í”„ë¡¬í”„íŠ¸ì—ì„œ í™œìš©í–ˆëŠ”ê°€?

3. **ì£¼ë„ì„± ë° ì˜¤ë¥˜ ìˆ˜ì • (Proactiveness):**
   - ì‚¬ìš©ìê°€ AIì˜ ì´ì „ ì˜¤ë¥˜ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì§€ì í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í–ˆëŠ”ê°€?
   - ì‚¬ìš©ìê°€ ëŠ¥ë™ì ìœ¼ë¡œ ê°œì„  ë°©í–¥ì„ ì œì‹œí•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í–ˆëŠ”ê°€?

4. **ì „ëµì  íƒìƒ‰ (Strategic Exploration):**
   - ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ì˜ ì˜ë„ê°€ HINT_OR_QUERYì—ì„œ OPTIMIZATIONìœ¼ë¡œ ì „í™˜ë˜ëŠ” ë“± ëŠ¥ë™ì ì¸ ë³€í™”ê°€ ìˆëŠ”ê°€?
   - ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ê°€ DEBUGGINGì—ì„œ TEST_CASEë¡œ ì „í™˜í•˜ëŠ” ë“± ì „ëµì  íƒìƒ‰ì„ ë³´ì—¬ì£¼ëŠ”ê°€?

5. **ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ ê¸°ë²• í™œìš© (Advanced Techniques Bonus):**
   - ì‚¬ìš©ìê°€ System Prompting, XML íƒœê·¸, Few-shot ì˜ˆì‹œ ë“± ê³ ê¸‰ ê¸°ë²•ì„ í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©í–ˆëŠ”ê°€?
   - ì´ëŸ¬í•œ ê¸°ë²• ì‚¬ìš© ì‹œ ë³´ë„ˆìŠ¤ ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ì„¸ìš”.

ê° í•­ëª©ì€ 0-100ì ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”.

**ì‘ë‹µ í˜•ì‹ (ë°˜ë“œì‹œ ë‹¤ìŒ JSON êµ¬ì¡°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”):**
```json
{{
    "problem_decomposition": 0-100,  // ë¬¸ì œ ë¶„í•´ ì ìˆ˜ (í•­ëª© 1)
    "feedback_integration": 0-100,  // í”¼ë“œë°± ìˆ˜ìš©ì„± ì ìˆ˜ (í•­ëª© 2)
    "strategic_exploration": 0-100,  // ì „ëµì  íƒìƒ‰ ì ìˆ˜ (í•­ëª© 4)
    "overall_flow_score": 0-100,  // ì¢…í•© ì ìˆ˜ (ëª¨ë“  í•­ëª©ì˜ ê°€ì¤‘ í‰ê· )
    "analysis": "ìƒì„¸ ë¶„ì„ ë‚´ìš©"
}}
```

**í•„ë“œ ë§¤í•‘ (í‰ê°€ ê¸°ì¤€ ìˆœì„œì™€ ì¼ì¹˜):**
- `problem_decomposition`: í•­ëª© 1 (ë¬¸ì œ ë¶„í•´) ì ìˆ˜
- `feedback_integration`: í•­ëª© 2 (í”¼ë“œë°± ìˆ˜ìš©ì„±) ì ìˆ˜
- `strategic_exploration`: í•­ëª© 4 (ì „ëµì  íƒìƒ‰) ì ìˆ˜
- `overall_flow_score`: ëª¨ë“  í•­ëª©ì„ ì¢…í•©í•œ ì „ì²´ ì ìˆ˜
- `analysis`: ìƒì„¸ ë¶„ì„ (í•­ëª© 3: ì£¼ë„ì„± ë° ì˜¤ë¥˜ ìˆ˜ì •, í•­ëª© 5: ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ ê¸°ë²• í¬í•¨)

**ì¤‘ìš”**: `analysis` í•„ë“œì—ëŠ” ë‹¤ìŒì„ í¬í•¨í•˜ì—¬ ìƒì„¸í•œ í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”:
- ë¬¸ì œ ë¶„í•´ ì „ëµì— ëŒ€í•œ êµ¬ì²´ì  í‰ê°€ (ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ê°€ ì–´ë–¤ ë¶€ë¶„ì´ ì˜ë˜ì—ˆê³ , ì–´ë–¤ ë¶€ë¶„ì„ ê°œì„ í•  ìˆ˜ ìˆëŠ”ì§€)
- í”¼ë“œë°± ìˆ˜ìš©ì„±ì— ëŒ€í•œ êµ¬ì²´ì  í‰ê°€ (ì‚¬ìš©ìê°€ ì´ì „ í„´ì˜ íŒíŠ¸ë¥¼ ì–´ë–»ê²Œ í”„ë¡¬í”„íŠ¸ì— ë°˜ì˜í–ˆëŠ”ì§€)
- **ì£¼ë„ì„± ë° ì˜¤ë¥˜ ìˆ˜ì •ì— ëŒ€í•œ êµ¬ì²´ì  í‰ê°€** (ì‚¬ìš©ìê°€ ì–´ë–»ê²Œ ëŠ¥ë™ì ìœ¼ë¡œ ê°œì„ ì„ ì œì‹œí•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í–ˆëŠ”ì§€, AIì˜ ì˜¤ë¥˜ë¥¼ ì–´ë–»ê²Œ ì§€ì í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í–ˆëŠ”ì§€)
- ì „ëµì  íƒìƒ‰ì— ëŒ€í•œ êµ¬ì²´ì  í‰ê°€ (ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ì˜ ì˜ë„ ì „í™˜ì´ ì–´ë–»ê²Œ ì´ë£¨ì–´ì¡ŒëŠ”ì§€)
- **ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ ê¸°ë²• í™œìš©ì— ëŒ€í•œ í‰ê°€** (ì‚¬ìš©ìê°€ XML íƒœê·¸, System Prompting, Few-shot ì˜ˆì‹œ ë“±ì„ ì–´ë–»ê²Œ í™œìš©í–ˆëŠ”ì§€)
- ì „ì²´ì ì¸ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ì²´ì´ë‹ ì „ëµì— ëŒ€í•œ ì¢…í•© ì˜ê²¬ ë° ê°œì„  ì œì•ˆ

**âš ï¸ í‰ê°€ ì‹œ ì£¼ì˜ì‚¬í•­:**
- AI ì‘ë‹µ í’ˆì§ˆì´ë‚˜ AIì˜ ì§€ì‹œ ì¤€ìˆ˜ ì—¬ë¶€ëŠ” í‰ê°€í•˜ì§€ ë§ˆì„¸ìš”
- ì ìˆ˜ëŠ” **ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ì˜ Chaining ì „ëµ í’ˆì§ˆ**ì—ë§Œ ê¸°ë°˜í•´ì•¼ í•©ë‹ˆë‹¤
- AI ì‘ë‹µ(ai_summary)ì€ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ì˜ ë§¥ë½ì„ ì´í•´í•˜ê¸° ìœ„í•œ ì°¸ê³ ìš©ì¼ ë¿ì…ë‹ˆë‹¤

**ì°¸ê³ **: í•­ëª© 3 (ì£¼ë„ì„± ë° ì˜¤ë¥˜ ìˆ˜ì •)ê³¼ í•­ëª© 5 (ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ ê¸°ë²• í™œìš©)ëŠ” ì ìˆ˜ì— í¬í•¨ë˜ì§€ ì•Šê³  `analysis` í•„ë“œì—ë§Œ í‰ê°€ ë‚´ìš©ì„ ì‘ì„±í•˜ì„¸ìš”."""


async def _eval_holistic_flow_impl(state: MainGraphState) -> Dict[str, Any]:
    """
    6a: ì „ì²´ í”Œë¡œìš° í‰ê°€ - ì „ëµ Chaining ë¶„ì„ (ë‚´ë¶€ êµ¬í˜„)
    
    í‰ê°€ í•­ëª©:
    1. ë¬¸ì œ ë¶„í•´ (Problem Decomposition)
    2. í”¼ë“œë°± ìˆ˜ìš©ì„± (Feedback Integration)
    3. ì£¼ë„ì„± ë° ì˜¤ë¥˜ ìˆ˜ì • (Proactiveness)
    4. ì „ëµì  íƒìƒ‰ (Strategic Exploration)
    """
    session_id = state.get("session_id", "unknown")
    logger.info(f"[6a. Eval Holistic Flow] ì§„ì… - session_id: {session_id}")
    
    try:
        # Redisì—ì„œ ëª¨ë“  turn_logs ì¡°íšŒ
        from app.infrastructure.cache.redis_client import redis_client
        all_turn_logs = await redis_client.get_all_turn_logs(session_id)
        
        logger.info(f"[6a. Eval Holistic Flow] í„´ ë¡œê·¸ ì¡°íšŒ - session_id: {session_id}, í„´ ê°œìˆ˜: {len(all_turn_logs)}")
        
        # Chaining í‰ê°€ë¥¼ ìœ„í•œ êµ¬ì¡°í™”ëœ ë¡œê·¸ ìƒì„±
        # PostgreSQLì—ì„œ ëª¨ë“  í„´ì˜ ai_summaryë¥¼ í•œ ë²ˆì— ì¡°íšŒ (ì„±ëŠ¥ ìµœì í™”)
        ai_summaries_map = {}  # {turn_num: ai_summary}
        try:
            from app.infrastructure.persistence.session import get_db_context
            from app.infrastructure.persistence.models.sessions import PromptEvaluation
            from app.infrastructure.persistence.models.enums import EvaluationTypeEnum
            from sqlalchemy import select, and_, text
            
            # session_idë¥¼ PostgreSQL idë¡œ ë³€í™˜
            postgres_session_id = int(session_id.replace("session_", "")) if session_id.startswith("session_") else None
            
            if postgres_session_id:
                turn_numbers = sorted([int(k) for k in all_turn_logs.keys()])
                if turn_numbers:
                    async with get_db_context() as db:
                        # ëª¨ë“  í„´ì˜ í‰ê°€ ê²°ê³¼ë¥¼ í•œ ë²ˆì— ì¡°íšŒ
                        query = select(PromptEvaluation).where(
                            and_(
                                PromptEvaluation.session_id == postgres_session_id,
                                PromptEvaluation.turn.in_(turn_numbers),
                                text("prompt_evaluations.evaluation_type::text = :eval_type")
                            )
                        )
                        result = await db.execute(query.params(eval_type=EvaluationTypeEnum.TURN_EVAL.value))
                        evaluations = result.scalars().all()
                        
                        # turnë³„ë¡œ ai_summary ë§¤í•‘
                        for evaluation in evaluations:
                            if evaluation.turn is not None and evaluation.details:
                                ai_summary = evaluation.details.get("ai_summary", "")
                                if ai_summary:
                                    ai_summaries_map[evaluation.turn] = ai_summary
                        
                        logger.debug(f"[6a. Eval Holistic Flow] PostgreSQLì—ì„œ ai_summary ì¡°íšŒ ì™„ë£Œ - {len(ai_summaries_map)}ê°œ í„´")
        except Exception as e:
            logger.debug(f"[6a. Eval Holistic Flow] PostgreSQLì—ì„œ ai_summary ì¡°íšŒ ì‹¤íŒ¨ (Redis ì‚¬ìš©) - error: {str(e)}")
        
        structured_logs = []
        for turn_num in sorted([int(k) for k in all_turn_logs.keys()]):
            log = all_turn_logs[str(turn_num)]
            
            # ai_summary ìš°ì„ ìˆœìœ„: PostgreSQL > Redis turn_log
            ai_summary = ai_summaries_map.get(turn_num) or log.get("llm_answer_summary", "") or log.get("answer_summary", "")
            
            structured_logs.append({
                "turn": turn_num,
                "intent": log.get("prompt_evaluation_details", {}).get("intent", "UNKNOWN"),
                "prompt_summary": log.get("user_prompt_summary", ""),
                "llm_reasoning": log.get("llm_answer_reasoning", ""),
                "ai_summary": ai_summary,  # AI ì‘ë‹µ ìš”ì•½ (Chaining ì „ëµ í‰ê°€ì— ì‚¬ìš©)
                "score": log.get("prompt_evaluation_details", {}).get("score", 0),
                "rubrics": log.get("prompt_evaluation_details", {}).get("rubrics", [])
            })
        
        if not structured_logs:
            logger.warning(f"[6a. Eval Holistic Flow] í„´ ë¡œê·¸ ì—†ìŒ - session_id: {session_id}")
            return {
                "holistic_flow_score": 0,
                "holistic_flow_analysis": "í„´ ë¡œê·¸ê°€ ì—†ì–´ í‰ê°€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "updated_at": datetime.utcnow().isoformat(),
            }
        
        # Holistic Flow í‰ê°€ Chain êµ¬ì„±
        problem_context = state.get("problem_context")
        
        def prepare_holistic_input(inputs: Dict[str, Any]) -> Dict[str, Any]:
            """Holistic í‰ê°€ ì…ë ¥ ì¤€ë¹„ (ë¬¸ì œ ì •ë³´ í¬í•¨)"""
            structured_logs = inputs.get("structured_logs", [])
            
            # ë¬¸ì œ ì •ë³´ë¥¼ í¬í•¨í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
            system_prompt = create_holistic_system_prompt(problem_context)
            
            user_prompt = f"""í„´ë³„ ëŒ€í™” ë¡œê·¸:

{json.dumps(structured_logs, ensure_ascii=False, indent=2)}

ìœ„ ë¡œê·¸ë¥¼ ë¶„ì„í•˜ì—¬ Chaining ì „ëµ ì ìˆ˜ë¥¼ í‰ê°€í•˜ì„¸ìš”."""
            
            return {
                "system_prompt": system_prompt,
                "user_prompt": user_prompt,
            }
        
        def format_holistic_messages(inputs: Dict[str, Any]) -> list:
            """ë©”ì‹œì§€ë¥¼ LangChain BaseMessage ê°ì²´ë¡œ ë³€í™˜"""
            from langchain_core.messages import HumanMessage, SystemMessage
            
            messages = []
            if inputs.get("system_prompt"):
                messages.append(SystemMessage(content=inputs["system_prompt"]))
            if inputs.get("user_prompt"):
                messages.append(HumanMessage(content=inputs["user_prompt"]))
            return messages
        
        def process_holistic_output_with_response(inputs: Dict[str, Any]) -> Dict[str, Any]:
            """ì¶œë ¥ ì²˜ë¦¬ (LLM ì‘ë‹µ ê°ì²´ í¬í•¨)"""
            # Chainì—ì„œ ì „ë‹¬ë˜ëŠ” í˜•íƒœ: {"llm_response": HolisticFlowEvaluation}
            if isinstance(inputs, dict):
                llm_response = inputs.get("llm_response")
            else:
                # ì§ì ‘ HolisticFlowEvaluation ê°ì²´ê°€ ì „ë‹¬ëœ ê²½ìš°
                llm_response = inputs
            
            if llm_response is None:
                logger.error(f"[Chain] process_holistic_output_with_response - llm_responseê°€ Noneì…ë‹ˆë‹¤. inputs íƒ€ì…: {type(inputs)}, inputs: {inputs}")
                raise ValueError("Holistic Flow í‰ê°€ ê²°ê³¼ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            result = llm_response  # structured_llmì˜ ê²°ê³¼ëŠ” ì´ë¯¸ HolisticFlowEvaluation ê°ì²´
            
            processed = {
                "holistic_flow_score": result.overall_flow_score,
                "holistic_flow_analysis": result.analysis,  # ì²´ì´ë‹ ì „ëµì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ (ë¬¸ì œ ë¶„í•´, í”¼ë“œë°± ìˆ˜ìš©ì„±, ì£¼ë„ì„±, ì „ëµì  íƒìƒ‰)
                "problem_decomposition": result.problem_decomposition,
                "feedback_integration": result.feedback_integration,
                "strategic_exploration": result.strategic_exploration,
                "updated_at": datetime.utcnow().isoformat(),
                "_llm_response": llm_response  # í† í° ì¶”ì¶œìš©
            }
            return processed
        
        # Chain êµ¬ì„± (í† í° ì¶”ì¶œì„ ìœ„í•´ ì›ë³¸ LLM ì‘ë‹µë„ ì „ë‹¬)
        llm = get_llm()
        structured_llm = llm.with_structured_output(HolisticFlowEvaluation)
        
        holistic_chain = (
            RunnableLambda(prepare_holistic_input)
            | RunnableLambda(format_holistic_messages)
            | structured_llm
            | RunnableLambda(lambda x: {"llm_response": x})
            | RunnableLambda(process_holistic_output_with_response)
        )
        
        try:
            # ì…ë ¥ ì¤€ë¹„ ë° ë©”ì‹œì§€ í¬ë§·íŒ…
            chain_input = {"structured_logs": structured_logs}
            prepared_input = prepare_holistic_input(chain_input)
            formatted_messages = format_holistic_messages(prepared_input)
            
            # ì›ë³¸ LLM í˜¸ì¶œ (1íšŒë§Œ - í† í° ì¶”ì¶œ + JSON íŒŒì‹±)
            logger.info(f"[6a. Eval Holistic Flow] ===== LLM í˜¸ì¶œ ì‹œì‘ =====")
            logger.info(f"[6a. Eval Holistic Flow] í‰ê°€ ëŒ€ìƒ í„´ ìˆ˜: {len(structured_logs)}")
            raw_response = await llm.ainvoke(formatted_messages)
            
            # LLM ì›ë³¸ ì‘ë‹µ ë¡œê·¸
            if hasattr(raw_response, 'content'):
                logger.info(f"[6a. Eval Holistic Flow] LLM ì›ë³¸ ì‘ë‹µ (ì²˜ìŒ 500ì): {raw_response.content[:500]}...")
            
            # í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ ë° Stateì— ëˆ„ì 
            tokens = extract_token_usage(raw_response)
            if tokens:
                accumulate_tokens(state, tokens, token_type="eval")
                logger.info(f"[6a. Eval Holistic Flow] í† í° ì‚¬ìš©ëŸ‰ - prompt: {tokens.get('prompt_tokens')}, completion: {tokens.get('completion_tokens')}, total: {tokens.get('total_tokens')}")
            else:
                logger.warning(f"[6a. Eval Holistic Flow] í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ ì‹¤íŒ¨ - raw_response íƒ€ì…: {type(raw_response)}")
            
            # ì›ë³¸ ì‘ë‹µì„ êµ¬ì¡°í™”ëœ ì¶œë ¥ìœ¼ë¡œ íŒŒì‹±
            logger.info(f"[6a. Eval Holistic Flow] êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì‹± ì‹œì‘...")
            try:
                from app.domain.langgraph.utils.structured_output_parser import parse_structured_output_async
                structured_result = await parse_structured_output_async(
                    raw_response=raw_response,
                    model_class=HolisticFlowEvaluation,
                    fallback_llm=structured_llm,
                    formatted_messages=formatted_messages
                )
            except Exception as parse_error:
                logger.error(f"[6a. Eval Holistic Flow] êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì‹± ì‹¤íŒ¨: {str(parse_error)}", exc_info=True)
                # íŒŒì‹± ì‹¤íŒ¨ ì‹œ fallbackìœ¼ë¡œ êµ¬ì¡°í™”ëœ ì¶œë ¥ Chain ì‚¬ìš©
                logger.info("[6a. Eval Holistic Flow] Fallback: êµ¬ì¡°í™”ëœ ì¶œë ¥ Chain ì‚¬ìš©")
                structured_result = await structured_llm.ainvoke(formatted_messages)
            
            # ì¶œë ¥ ì²˜ë¦¬ (State í˜•ì‹ìœ¼ë¡œ ë³€í™˜)
            result = {
                "holistic_flow_score": structured_result.overall_flow_score,
                "holistic_flow_analysis": structured_result.analysis,
                "problem_decomposition": structured_result.problem_decomposition,
                "feedback_integration": structured_result.feedback_integration,
                "strategic_exploration": structured_result.strategic_exploration,
                "updated_at": datetime.utcnow().isoformat(),
            }
            logger.info(f"[6a. Eval Holistic Flow] êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì‹± ì™„ë£Œ")
            
            # Stateì— ëˆ„ì ëœ í† í° ì •ë³´ë¥¼ resultì— í¬í•¨ (LangGraph ë³‘í•©ì„ ìœ„í•´)
            if "eval_tokens" in state:
                result["eval_tokens"] = state["eval_tokens"]
            
            # í‰ê°€ ê²°ê³¼ ë¡œê¹… (ìƒì„¸ ë¶„ì„ í¬í•¨)
            analysis = result.get("holistic_flow_analysis", "")
            score = result.get("holistic_flow_score")
            logger.info(f"[6a. Eval Holistic Flow] ===== í‰ê°€ ì™„ë£Œ =====")
            logger.info(f"[6a. Eval Holistic Flow] Holistic Flow Score: {score}")
            logger.info(f"[6a. Eval Holistic Flow] Problem Decomposition: {result.get('problem_decomposition')}")
            logger.info(f"[6a. Eval Holistic Flow] Feedback Integration: {result.get('feedback_integration')}")
            logger.info(f"[6a. Eval Holistic Flow] Strategic Exploration: {result.get('strategic_exploration')}")
            if analysis:
                logger.info(f"[6a. Eval Holistic Flow] Analysis (ì²˜ìŒ 500ì): {analysis[:500]}...")
                logger.info(f"[6a. Eval Holistic Flow] ì „ì²´ Analysis ê¸¸ì´: {len(analysis)} ë¬¸ì")
                
                # ì „ì²´ ë¶„ì„ í…ìŠ¤íŠ¸ JSON ì¶œë ¥ (ë°œí‘œìë£Œìš©)
                analysis_json = {
                    "session_id": session_id,
                    "holistic_flow_score": score,
                    "problem_decomposition": result.get('problem_decomposition'),
                    "feedback_integration": result.get('feedback_integration'),
                    "strategic_exploration": result.get('strategic_exploration'),
                    "analysis_text": analysis
                }
                logger.info("")
                logger.info(f"[6a. Eval Holistic Flow] ===== Holistic Flow í‰ê°€ ë¶„ì„ í…ìŠ¤íŠ¸ (JSON) =====")
                logger.info(json.dumps(analysis_json, indent=4, ensure_ascii=False))
                logger.info("")
            else:
                logger.warning(f"[6a. Eval Holistic Flow] ë¶„ì„ ë‚´ìš© ì—†ìŒ - session_id: {session_id}")
            
            # PostgreSQLì— í‰ê°€ ê²°ê³¼ ì €ì¥
            try:
                from app.infrastructure.persistence.session import get_db_context
                from app.application.services.evaluation_storage_service import EvaluationStorageService
                
                # session_idë¥¼ PostgreSQL idë¡œ ë³€í™˜ (Redis session_id: "session_123" -> PostgreSQL id: 123)
                postgres_session_id = int(session_id.replace("session_", "")) if session_id.startswith("session_") else None
                
                if postgres_session_id and score is not None:
                    async with get_db_context() as db:
                        storage_service = EvaluationStorageService(db)
                        
                        # ìƒì„¸ ì •ë³´ êµ¬ì„±
                        details = {
                            "problem_decomposition": result.get("problem_decomposition"),
                            "feedback_integration": result.get("feedback_integration"),
                            "strategic_exploration": result.get("strategic_exploration"),
                            "structured_logs": structured_logs,  # í„´ë³„ ë¡œê·¸ ì •ë³´
                        }
                        
                        await storage_service.save_holistic_flow_evaluation(
                            session_id=postgres_session_id,
                            holistic_flow_score=score,
                            holistic_flow_analysis=analysis or "",
                            details=details
                        )
                        await db.commit()
                        logger.info(
                            f"[6a. Eval Holistic Flow] PostgreSQL ì €ì¥ ì™„ë£Œ - "
                            f"session_id: {postgres_session_id}, score: {score}"
                        )
            except Exception as pg_error:
                # PostgreSQL ì €ì¥ ì‹¤íŒ¨í•´ë„ RedisëŠ” ì €ì¥ë˜ì—ˆìœ¼ë¯€ë¡œ ê²½ê³ ë§Œ
                logger.warning(
                    f"[6a. Eval Holistic Flow] PostgreSQL ì €ì¥ ì‹¤íŒ¨ (RedisëŠ” ì €ì¥ë¨) - "
                    f"session_id: {session_id}, error: {str(pg_error)}"
                )
            
            # LangSmith ì¶”ì  ì •ë³´ ë¡œê¹…
            if should_enable_langsmith(state):
                logger.debug(f"[LangSmith] 6a ë…¸ë“œ ì¶”ì  í™œì„±í™” - session_id: {session_id}, í„´ ê°œìˆ˜: {len(structured_logs)}")
            
            return result
            
        except Exception as e:
            logger.error(f"[6a. Eval Holistic Flow] LLM í‰ê°€ ì˜¤ë¥˜ - session_id: {session_id}, error: {str(e)}", exc_info=True)
            return {
                "holistic_flow_score": None,
                "holistic_flow_analysis": None,
                "error_message": f"Holistic flow í‰ê°€ ì‹¤íŒ¨: {str(e)}",
                "updated_at": datetime.utcnow().isoformat(),
            }
            
    except Exception as e:
        logger.error(f"[6a. Eval Holistic Flow] ì˜¤ë¥˜ - session_id: {session_id}, error: {str(e)}", exc_info=True)
        return {
            "holistic_flow_score": None,
            "holistic_flow_analysis": None,
            "error_message": f"Holistic flow í‰ê°€ ì‹¤íŒ¨: {str(e)}",
            "updated_at": datetime.utcnow().isoformat(),
        }


# ===== ì™¸ë¶€ ë˜í¼ í•¨ìˆ˜ =====

async def eval_holistic_flow(state: MainGraphState) -> Dict[str, Any]:
    """
    6a: ì „ì²´ í”Œë¡œìš° í‰ê°€ - ì „ëµ Chaining ë¶„ì„
    
    LangSmith ì¶”ì :
    - Stateì˜ enable_langsmith_tracing ê°’ì— ë”°ë¼ í™œì„±í™”/ë¹„í™œì„±í™”
    - Noneì´ë©´ í™˜ê²½ ë³€ìˆ˜ LANGCHAIN_TRACING_V2 ì‚¬ìš©
    
    ì‚¬ìš© ì˜ˆì‹œ:
    - Stateì— enable_langsmith_tracing=True ì„¤ì • ì‹œ ì¶”ì  í™œì„±í™”
    - Stateì— enable_langsmith_tracing=False ì„¤ì • ì‹œ ì¶”ì  ë¹„í™œì„±í™”
    - Stateì— enable_langsmith_tracing=None ì„¤ì • ì‹œ í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©
    """
    # LangSmith ì¶”ì ê³¼ í•¨ê»˜ ë˜í•‘
    wrapped_func = wrap_node_with_tracing(
        node_name=TRACE_NAME_HOLISTIC_FLOW,
        impl_func=_eval_holistic_flow_impl,
        state=state
    )
    return await wrapped_func(state)

