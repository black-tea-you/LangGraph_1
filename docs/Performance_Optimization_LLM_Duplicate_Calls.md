# LLM ì¤‘ë³µ í˜¸ì¶œ ì„±ëŠ¥ ìµœì í™”

## ğŸ” ë¬¸ì œ ë¶„ì„

### í˜„ì¬ ë¬¸ì œì 

#### 1. 4ë²ˆ ë…¸ë“œ (Turn Evaluator) - LLM ì¤‘ë³µ í˜¸ì¶œ

**ìœ„ì¹˜**: `app/domain/langgraph/nodes/turn_evaluator/evaluators.py`

**ë¬¸ì œ**:
- `_evaluate_turn` í•¨ìˆ˜ì—ì„œ **LLMì„ ë‘ ë²ˆ í˜¸ì¶œ**:
  1. ì²« ë²ˆì§¸: ì›ë³¸ LLM í˜¸ì¶œ (í† í° ì¶”ì¶œìš©) - line 261
  2. ë‘ ë²ˆì§¸: êµ¬ì¡°í™”ëœ ì¶œë ¥ Chain ì‹¤í–‰ (í‰ê°€ìš©) - line 272

**ì½”ë“œ**:
```python
# ì›ë³¸ LLM í˜¸ì¶œ (í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œìš©)
raw_response = await llm.ainvoke(formatted_messages)

# í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ
tokens = extract_token_usage(raw_response)
accumulate_tokens(state, tokens, token_type="eval")

# í‰ê°€ Chain ì‹¤í–‰ (êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì‹±) - ì—¬ê¸°ì„œ LLMì„ ë‹¤ì‹œ í˜¸ì¶œ!
chain_result = await chain.ainvoke(chain_input)
```

**ì˜í–¥**:
- ê° í‰ê°€ í•¨ìˆ˜ë§ˆë‹¤ LLMì„ 2ë²ˆ í˜¸ì¶œ
- 8ê°œ í‰ê°€ í•¨ìˆ˜ê°€ ìˆë‹¤ë©´ ì´ **16ë²ˆì˜ LLM í˜¸ì¶œ**
- ì‹œê°„ì´ **2ë°°**ë¡œ ì†Œìš”ë¨

#### 2. 6ë²ˆ ë…¸ë“œ 6.a (Holistic Flow Evaluator) - LLM ì¤‘ë³µ í˜¸ì¶œ

**ìœ„ì¹˜**: `app/domain/langgraph/nodes/holistic_evaluator/flow.py`

**ë¬¸ì œ**:
- ë™ì¼í•œ ë¬¸ì œ: LLMì„ ë‘ ë²ˆ í˜¸ì¶œ
  1. ì²« ë²ˆì§¸: ì›ë³¸ LLM í˜¸ì¶œ (í† í° ì¶”ì¶œìš©) - line 231
  2. ë‘ ë²ˆì§¸: êµ¬ì¡°í™”ëœ ì¶œë ¥ Chain ì‹¤í–‰ (í‰ê°€ìš©) - line 247

**ì˜í–¥**:
- Holistic Flow í‰ê°€ë§ˆë‹¤ LLMì„ 2ë²ˆ í˜¸ì¶œ
- ì‹œê°„ì´ **2ë°°**ë¡œ ì†Œìš”ë¨

---

## ğŸ’¡ í•´ê²° ë°©ì•ˆ

### ë°©ì•ˆ 1: êµ¬ì¡°í™”ëœ ì¶œë ¥ì—ì„œ í† í° ì¶”ì¶œ (ê¶Œì¥)

**í•µì‹¬ ì•„ì´ë””ì–´**: `with_structured_output`ì˜ ë‚´ë¶€ LLM í˜¸ì¶œì—ì„œ í† í°ì„ ì¶”ì¶œ

**êµ¬í˜„ ë°©ë²•**:
1. `with_structured_output`ì€ ë‚´ë¶€ì ìœ¼ë¡œ LLMì„ í˜¸ì¶œ
2. í˜¸ì¶œ ê²°ê³¼ì—ì„œ í† í° ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ìˆì–´ì•¼ í•¨
3. LangChainì˜ `invoke`/`ainvoke`ëŠ” ì‘ë‹µ ë©”íƒ€ë°ì´í„°ë¥¼ í¬í•¨í•  ìˆ˜ ìˆìŒ

**ì½”ë“œ ì˜ˆì‹œ**:
```python
async def _evaluate_turn_optimized(state: EvalTurnState, eval_type: str, criteria: str) -> Dict[str, Any]:
    """ìµœì í™”ëœ í„´ í‰ê°€ (LLM 1íšŒ í˜¸ì¶œ)"""
    try:
        # í‰ê°€ Chain ìƒì„±
        chain = create_evaluation_chain(eval_type, criteria)
        
        chain_input = {"state": state}
        
        # Chain ì‹¤í–‰ (êµ¬ì¡°í™”ëœ ì¶œë ¥)
        # with_structured_outputì€ ë‚´ë¶€ì ìœ¼ë¡œ LLMì„ í˜¸ì¶œí•˜ë¯€ë¡œ
        # ì‘ë‹µ ë©”íƒ€ë°ì´í„°ì—ì„œ í† í°ì„ ì¶”ì¶œí•  ìˆ˜ ìˆì–´ì•¼ í•¨
        chain_result = await chain.ainvoke(chain_input)
        
        # Chain ì‹¤í–‰ í›„ ì‘ë‹µ ë©”íƒ€ë°ì´í„° í™•ì¸
        # LangChainì˜ ì‘ë‹µ ê°ì²´ëŠ” response_metadataë¥¼ í¬í•¨í•  ìˆ˜ ìˆìŒ
        if hasattr(chain_result, 'response_metadata'):
            tokens = extract_token_usage_from_metadata(chain_result.response_metadata)
            if tokens:
                accumulate_tokens(state, tokens, token_type="eval")
        
        # ë˜ëŠ” Chain ë‚´ë¶€ì—ì„œ í† í° ì •ë³´ë¥¼ ì „ë‹¬í•˜ë„ë¡ ìˆ˜ì •
        # ...
        
        return chain_result
```

**ë¬¸ì œì **:
- `with_structured_output`ì˜ ì‘ë‹µì€ Pydantic ëª¨ë¸ì´ë¯€ë¡œ ë©”íƒ€ë°ì´í„°ê°€ ì—†ì„ ìˆ˜ ìˆìŒ
- LangChainì˜ êµ¬ì¡°í™”ëœ ì¶œë ¥ì€ ì›ë³¸ ì‘ë‹µ ë©”íƒ€ë°ì´í„°ë¥¼ ë³´ì¡´í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ

### ë°©ì•ˆ 2: êµ¬ì¡°í™”ëœ ì¶œë ¥ Chain ë‚´ë¶€ì—ì„œ í† í° ì¶”ì¶œ (ê¶Œì¥)

**í•µì‹¬ ì•„ì´ë””ì–´**: Chain ë‚´ë¶€ì—ì„œ ì›ë³¸ LLM ì‘ë‹µì„ ìº¡ì²˜í•˜ì—¬ í† í° ì¶”ì¶œ

**êµ¬í˜„ ë°©ë²•**:
1. Chain ë‚´ë¶€ì—ì„œ ì›ë³¸ LLM í˜¸ì¶œ
2. ì›ë³¸ ì‘ë‹µì—ì„œ í† í° ì¶”ì¶œ
3. êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì‹±
4. í† í° ì •ë³´ë¥¼ Chain ê²°ê³¼ì— í¬í•¨

**ì½”ë“œ ì˜ˆì‹œ**:
```python
def create_evaluation_chain_optimized(eval_type: str, criteria: str):
    """ìµœì í™”ëœ í‰ê°€ Chain (LLM 1íšŒ í˜¸ì¶œ)"""
    llm = get_llm()
    structured_llm = llm.with_structured_output(TurnEvaluation)
    
    async def call_llm_and_extract_tokens(inputs: Dict[str, Any]) -> Dict[str, Any]:
        """LLM í˜¸ì¶œ ë° í† í° ì¶”ì¶œ (ë¹„ë™ê¸°)"""
        messages = inputs.get("messages", [])
        
        # ì›ë³¸ LLM í˜¸ì¶œ (í† í° ì¶”ì¶œìš©)
        raw_response = await llm.ainvoke(messages)
        
        # í† í° ì¶”ì¶œ
        tokens = extract_token_usage(raw_response)
        
        # êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì‹± (ë™ì¼í•œ ë©”ì‹œì§€ë¡œ)
        # ì£¼ì˜: structured_llmì€ ë‚´ë¶€ì ìœ¼ë¡œ LLMì„ ë‹¤ì‹œ í˜¸ì¶œí•˜ë¯€ë¡œ
        # ì´ ë°©ë²•ë„ ì—¬ì „íˆ 2ë²ˆ í˜¸ì¶œë¨
        
        # ëŒ€ì•ˆ: ì›ë³¸ ì‘ë‹µì„ ì§ì ‘ íŒŒì‹±
        structured_result = parse_structured_output(raw_response, TurnEvaluation)
        
        return {
            "structured_result": structured_result,
            "tokens": tokens,  # í† í° ì •ë³´ í¬í•¨
        }
    
    chain = (
        RunnableLambda(prepare_evaluation_input)
        | RunnableLambda(format_messages)
        | RunnableLambda(call_llm_and_extract_tokens)  # ë¹„ë™ê¸° í•¨ìˆ˜ëŠ” RunnableLambdaë¡œ ì§ì ‘ ì‚¬ìš© ë¶ˆê°€
        | RunnableLambda(process_output_with_response)
    )
    
    return chain
```

**ë¬¸ì œì **:
- `RunnableLambda`ëŠ” ë¹„ë™ê¸° í•¨ìˆ˜ë¥¼ ì§ì ‘ ì§€ì›í•˜ì§€ ì•ŠìŒ
- `with_structured_output`ì€ ë‚´ë¶€ì ìœ¼ë¡œ LLMì„ ë‹¤ì‹œ í˜¸ì¶œí•˜ë¯€ë¡œ ì—¬ì „íˆ 2ë²ˆ í˜¸ì¶œë¨

### ë°©ì•ˆ 3: ì›ë³¸ ì‘ë‹µì„ ì§ì ‘ íŒŒì‹± (ìµœì )

**í•µì‹¬ ì•„ì´ë””ì–´**: ì›ë³¸ LLM ì‘ë‹µì„ ë°›ì•„ì„œ ì§ì ‘ êµ¬ì¡°í™”ëœ ì¶œë ¥ìœ¼ë¡œ íŒŒì‹±

**êµ¬í˜„ ë°©ë²•**:
1. ì›ë³¸ LLM í˜¸ì¶œ (1íšŒ)
2. ì›ë³¸ ì‘ë‹µì—ì„œ í† í° ì¶”ì¶œ
3. ì›ë³¸ ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•˜ì—¬ Pydantic ëª¨ë¸ë¡œ ë³€í™˜

**ì½”ë“œ ì˜ˆì‹œ**:
```python
async def _evaluate_turn_optimized_v2(state: EvalTurnState, eval_type: str, criteria: str) -> Dict[str, Any]:
    """ìµœì í™”ëœ í„´ í‰ê°€ (LLM 1íšŒ í˜¸ì¶œ, ì›ë³¸ ì‘ë‹µ ì§ì ‘ íŒŒì‹±)"""
    try:
        chain_input = {"state": state}
        
        # ë©”ì‹œì§€ í¬ë§·íŒ…
        prepared_input = prepare_evaluation_input_internal(chain_input, eval_type, criteria)
        formatted_messages = format_evaluation_messages(prepared_input)
        
        # ì›ë³¸ LLM í˜¸ì¶œ (1íšŒë§Œ!)
        llm = get_llm()
        raw_response = await llm.ainvoke(formatted_messages)
        
        # í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ
        tokens = extract_token_usage(raw_response)
        if tokens:
            accumulate_tokens(state, tokens, token_type="eval")
        
        # ì›ë³¸ ì‘ë‹µì„ êµ¬ì¡°í™”ëœ ì¶œë ¥ìœ¼ë¡œ íŒŒì‹±
        # ë°©ë²• 1: JSON ëª¨ë“œ ì‚¬ìš© (GeminiëŠ” JSON ëª¨ë“œ ì§€ì›)
        if hasattr(raw_response, 'content'):
            content = raw_response.content
            # JSON íŒŒì‹±
            import json
            try:
                # JSON ì‘ë‹µ íŒŒì‹±
                if isinstance(content, str):
                    # JSON ë¬¸ìì—´ì¸ ê²½ìš°
                    parsed_json = json.loads(content)
                else:
                    # ì´ë¯¸ dictì¸ ê²½ìš°
                    parsed_json = content
                
                # Pydantic ëª¨ë¸ë¡œ ë³€í™˜
                structured_result = TurnEvaluation(**parsed_json)
            except (json.JSONDecodeError, ValueError) as e:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ fallback: êµ¬ì¡°í™”ëœ ì¶œë ¥ Chain ì‚¬ìš©
                logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨, êµ¬ì¡°í™”ëœ ì¶œë ¥ Chain ì‚¬ìš©: {e}")
                structured_llm = llm.with_structured_output(TurnEvaluation)
                structured_result = await structured_llm.ainvoke(formatted_messages)
        
        # ê²°ê³¼ ì²˜ë¦¬
        result = {
            "intent": structured_result.intent,
            "score": structured_result.score,
            "average": structured_result.score,
            "rubrics": [r.dict() for r in structured_result.rubrics],
            "final_reasoning": structured_result.final_reasoning,
        }
        
        # Stateì— ëˆ„ì ëœ í† í° ì •ë³´ë¥¼ resultì— í¬í•¨
        if "eval_tokens" in state:
            result["eval_tokens"] = state["eval_tokens"]
        
        return result
```

**ì¥ì **:
- âœ… LLM í˜¸ì¶œ 1íšŒë§Œ
- âœ… í† í° ì¶”ì¶œ ê°€ëŠ¥
- âœ… êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì‹± ê°€ëŠ¥

**ë‹¨ì **:
- âŒ LLMì´ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ
- âŒ JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ fallback í•„ìš”

### ë°©ì•ˆ 4: JSON ëª¨ë“œ ì‚¬ìš© (Gemini ì§€ì›)

**í•µì‹¬ ì•„ì´ë””ì–´**: Geminiì˜ JSON ëª¨ë“œ ì‚¬ìš©í•˜ì—¬ êµ¬ì¡°í™”ëœ ì¶œë ¥ ì§ì ‘ ë°›ê¸°

**êµ¬í˜„ ë°©ë²•**:
1. LLM í˜¸ì¶œ ì‹œ JSON ëª¨ë“œ í™œì„±í™”
2. JSON ì‘ë‹µì„ ì§ì ‘ ë°›ì•„ì„œ Pydantic ëª¨ë¸ë¡œ íŒŒì‹±
3. í† í° ì •ë³´ëŠ” ì‘ë‹µ ë©”íƒ€ë°ì´í„°ì—ì„œ ì¶”ì¶œ

**ì½”ë“œ ì˜ˆì‹œ**:
```python
async def _evaluate_turn_optimized_v3(state: EvalTurnState, eval_type: str, criteria: str) -> Dict[str, Any]:
    """ìµœì í™”ëœ í„´ í‰ê°€ (JSON ëª¨ë“œ ì‚¬ìš©)"""
    try:
        chain_input = {"state": state}
        
        # ë©”ì‹œì§€ í¬ë§·íŒ…
        prepared_input = prepare_evaluation_input_internal(chain_input, eval_type, criteria)
        formatted_messages = format_evaluation_messages(prepared_input)
        
        # JSON ëª¨ë“œë¡œ LLM í˜¸ì¶œ
        llm = get_llm()
        
        # Gemini JSON ëª¨ë“œ ì„¤ì •
        # ì£¼ì˜: ChatGoogleGenerativeAIëŠ” response_format íŒŒë¼ë¯¸í„° ì§€ì› ì—¬ë¶€ í™•ì¸ í•„ìš”
        # ë˜ëŠ” í”„ë¡¬í”„íŠ¸ì— JSON í˜•ì‹ ìš”ì²­ ì¶”ê°€
        
        # JSON í˜•ì‹ ìš”ì²­ì„ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
        json_format_prompt = """
ë‹¤ìŒ í˜•ì‹ì˜ JSONìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{
  "intent": "ì˜ë„",
  "score": 0-100,
  "rubrics": [...],
  "final_reasoning": "..."
}
"""
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— JSON í˜•ì‹ ìš”ì²­ ì¶”ê°€
        formatted_messages[0].content += "\n\n" + json_format_prompt
        
        # LLM í˜¸ì¶œ (1íšŒë§Œ!)
        raw_response = await llm.ainvoke(formatted_messages)
        
        # í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ
        tokens = extract_token_usage(raw_response)
        if tokens:
            accumulate_tokens(state, tokens, token_type="eval")
        
        # JSON íŒŒì‹±
        import json
        import re
        
        content = raw_response.content
        
        # JSON ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
        json_match = re.search(r'\{.*\}', content, re.DOTALL)
        if json_match:
            json_str = json_match.group(0)
            parsed_json = json.loads(json_str)
            structured_result = TurnEvaluation(**parsed_json)
        else:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ fallback
            structured_llm = llm.with_structured_output(TurnEvaluation)
            structured_result = await structured_llm.ainvoke(formatted_messages)
        
        # ê²°ê³¼ ì²˜ë¦¬
        result = {
            "intent": structured_result.intent,
            "score": structured_result.score,
            "average": structured_result.score,
            "rubrics": [r.dict() for r in structured_result.rubrics],
            "final_reasoning": structured_result.final_reasoning,
        }
        
        if "eval_tokens" in state:
            result["eval_tokens"] = state["eval_tokens"]
        
        return result
```

---

## ğŸ¯ ìµœì¢… ì¶”ì²œ ë°©ì•ˆ

### ë‹¨ê¸° í•´ê²°ì±…: ë°©ì•ˆ 3 (ì›ë³¸ ì‘ë‹µ ì§ì ‘ íŒŒì‹±)

**ì´ìœ **:
- âœ… êµ¬í˜„ì´ ê°„ë‹¨í•¨
- âœ… LLM í˜¸ì¶œ 1íšŒë¡œ ìµœì í™”
- âœ… ê¸°ì¡´ ì½”ë“œ êµ¬ì¡° ìµœì†Œ ë³€ê²½

**êµ¬í˜„ ë‹¨ê³„**:
1. `_evaluate_turn` í•¨ìˆ˜ ìˆ˜ì •
2. ì›ë³¸ LLM í˜¸ì¶œ í›„ JSON íŒŒì‹±
3. íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ `with_structured_output` ì‚¬ìš© (fallback)

### ì¥ê¸° í•´ê²°ì±…: ë°©ì•ˆ 4 (JSON ëª¨ë“œ ì‚¬ìš©)

**ì´ìœ **:
- âœ… ê°€ì¥ íš¨ìœ¨ì  (LLM í˜¸ì¶œ 1íšŒ)
- âœ… êµ¬ì¡°í™”ëœ ì¶œë ¥ ë³´ì¥
- âœ… í† í° ì¶”ì¶œ ê°€ëŠ¥

**êµ¬í˜„ ë‹¨ê³„**:
1. Gemini JSON ëª¨ë“œ ì§€ì› í™•ì¸
2. í”„ë¡¬í”„íŠ¸ì— JSON í˜•ì‹ ìš”ì²­ ì¶”ê°€
3. JSON íŒŒì‹± ë¡œì§ êµ¬í˜„
4. Fallback ë©”ì»¤ë‹ˆì¦˜ ì¶”ê°€

---

## ğŸ“Š ì˜ˆìƒ ì„±ëŠ¥ ê°œì„ 

### í˜„ì¬ (LLM 2íšŒ í˜¸ì¶œ)
- 4ë²ˆ ë…¸ë“œ: 8ê°œ í‰ê°€ Ã— 2íšŒ = **16íšŒ LLM í˜¸ì¶œ**
- 6.a ë…¸ë“œ: **2íšŒ LLM í˜¸ì¶œ**
- **ì´ ì†Œìš” ì‹œê°„**: T Ã— 2

### ìµœì í™” í›„ (LLM 1íšŒ í˜¸ì¶œ)
- 4ë²ˆ ë…¸ë“œ: 8ê°œ í‰ê°€ Ã— 1íšŒ = **8íšŒ LLM í˜¸ì¶œ**
- 6.a ë…¸ë“œ: **1íšŒ LLM í˜¸ì¶œ**
- **ì´ ì†Œìš” ì‹œê°„**: T Ã— 1

**ì„±ëŠ¥ ê°œì„ **: **ì•½ 50% ì‹œê°„ ë‹¨ì¶•**

---

## ğŸ”§ êµ¬í˜„ ìš°ì„ ìˆœìœ„

1. **ë†’ìŒ**: 4ë²ˆ ë…¸ë“œ ìµœì í™” (ê°€ì¥ ë§ì€ LLM í˜¸ì¶œ)
2. **ë†’ìŒ**: 6.a ë…¸ë“œ ìµœì í™” (ê¸´ í”„ë¡¬í”„íŠ¸ë¡œ ì¸í•œ ê¸´ ì‘ë‹µ ì‹œê°„)
3. **ì¤‘ê°„**: ë‹¤ë¥¸ ë…¸ë“œë“¤ë„ ë™ì¼í•œ íŒ¨í„´ í™•ì¸ ë° ìµœì í™”









